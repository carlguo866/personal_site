---
title: "MIT AI Alignment"
subtitle: "Raising awareness for AI risks"
category: Experience
dateOverride: "Sep '22 - Present"
showRelatedTag: null
highlightSubtitle: true
titleLinked: true
weight: 2
---

I help organize events for [MIT AI Alignment (MAIA)](https://www.mitalignment.org/), a student group for people to upskill in AI safety & alignment so they can conduct original research.
<br>

- I help organize weekly [AGI Safety Foundamentals](https://www.agisafetyfundamentals.com/ai-alignment-curriculum) series for 80+ MIT students and speaker series of leading researchers, including Chris Olah and Neel Nanda.

- I'm a member of the joint Strategy Team between MAIA and [Harvard AI Safety Team (HAIST)](https://haist.ai/), where I think about building the field of AI safety in China and promoting international collobarations.

- I'm one of the main authors of a letter for MIT President Sally Kornbluth on AI safety.

- I taught myself [AGI Safety Foundamentals](https://www.agisafetyfundamentals.com/ai-alignment-curriculum), supported by a scholarship from [AI Safety Support](https://www.aisafetysupport.org/).
